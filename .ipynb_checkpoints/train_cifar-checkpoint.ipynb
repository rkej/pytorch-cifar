{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import torchvision\n",
    "import sys\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "from torchvision.datasets import CIFAR10 as data_cifar\n",
    "from torchvision.transforms import Normalize, ToTensor, Compose, RandomCrop, RandomHorizontalFlip\n",
    "from easydict import EasyDict\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bd4404bebd48efbf0abb73c90cf384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "args = EasyDict({\"lr\": 0.1, \"resume\":False})\n",
    "\n",
    "transform_train = Compose([\n",
    "    RandomCrop(32, padding=4),\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "trainset = data_cifar(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = data_cifar(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of training set is 50000\n",
      "The length of testing set is: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"The length of training set is\", len(trainset))\n",
    "print(\"The length of testing set is:\", len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current lr 1.00000e-01\n",
      "\n",
      "Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "net = resnet.ResNetUse()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=args.lr ,\n",
    "                      momentum=0.9, weight_decay = 1e-4)\n",
    "\n",
    "# Training\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30,40], gamma=0.1)\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, targets)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_loss += loss.item()\n",
    "      _, predicted = outputs.max(1)\n",
    "      total += targets.size(0)\n",
    "      correct += predicted.eq(targets).sum().item()\n",
    "    print(\"The training accuracy is:\", correct/total)\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    print(\"The testing accuracy is:\", correct/total)\n",
    "\n",
    "for epoch in range(0, 50):\n",
    "    print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
    "    train(epoch)\n",
    "    scheduler.step()\n",
    "    test(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
